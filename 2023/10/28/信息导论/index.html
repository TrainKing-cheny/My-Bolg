<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Information Theory and Coding | 喜欢我火车王吗？</title><meta name="author" content="TrainKing"><meta name="copyright" content="TrainKing"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="信息导论笔记，斜体部分了解即可  Chapter 1 离散信源与信息熵概述：本章知识结构可以大致概括为： 1.信息 2.单符号离散信源 3.信息量 4.熵以及熵的性质 信息信息定义很多，不多做赘述。 就本科目所学知识而言，信息是对不确定性的描述，不确定的东西才有研究的价值，延伸至其他领域，随机变量这一研究对象则很符合这样的“不确定性”，所以我们可以理解为信息是对随机变量不确定性的描述。 通信系统的">
<meta property="og:type" content="article">
<meta property="og:title" content="Information Theory and Coding">
<meta property="og:url" content="http://example.com/2023/10/28/%E4%BF%A1%E6%81%AF%E5%AF%BC%E8%AE%BA/index.html">
<meta property="og:site_name" content="喜欢我火车王吗？">
<meta property="og:description" content="信息导论笔记，斜体部分了解即可  Chapter 1 离散信源与信息熵概述：本章知识结构可以大致概括为： 1.信息 2.单符号离散信源 3.信息量 4.熵以及熵的性质 信息信息定义很多，不多做赘述。 就本科目所学知识而言，信息是对不确定性的描述，不确定的东西才有研究的价值，延伸至其他领域，随机变量这一研究对象则很符合这样的“不确定性”，所以我们可以理解为信息是对随机变量不确定性的描述。 通信系统的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s1.ax1x.com/2023/05/23/p9TireU.jpg">
<meta property="article:published_time" content="2023-10-28T06:07:32.282Z">
<meta property="article:modified_time" content="2023-05-25T15:11:20.000Z">
<meta property="article:author" content="TrainKing">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s1.ax1x.com/2023/05/23/p9TireU.jpg"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="http://example.com/2023/10/28/%E4%BF%A1%E6%81%AF%E5%AF%BC%E8%AE%BA/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Information Theory and Coding',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-05-25 23:11:20'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="/css/font.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页捏捏</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 这是分类捏</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 这是归档捏</span></a></div><div class="menus_item"><a class="site-page" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 看看图片捏</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 听听音乐捏</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s1.ax1x.com/2023/05/23/p9TireU.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">喜欢我火车王吗？</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页捏捏</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 这是分类捏</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 这是归档捏</span></a></div><div class="menus_item"><a class="site-page" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 看看图片捏</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 听听音乐捏</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Information Theory and Coding</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-10-28T06:07:32.282Z" title="发表于 2023-10-28 14:07:32">2023-10-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-25T15:11:20.000Z" title="更新于 2023-05-25 23:11:20">2023-05-25</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Information Theory and Coding"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>信息导论笔记，斜体部分了解即可</p>
<hr>
<h1 id="Chapter-1-离散信源与信息熵"><a href="#Chapter-1-离散信源与信息熵" class="headerlink" title="Chapter 1 离散信源与信息熵"></a>Chapter 1 离散信源与信息熵</h1><p>概述：本章知识结构可以大致概括为：</p>
<p>1.信息</p>
<p>2.单符号离散信源</p>
<p>3.信息量</p>
<p>4.熵以及熵的性质</p>
<h2 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h2><p>信息定义很多，不多做赘述。</p>
<p>就本科目所学知识而言，信息是对不确定性的描述，不确定的东西才有研究的价值，延伸至其他领域，随机变量这一研究对象则很符合这样的“不确定性”，所以我们可以理解为<strong>信息是对随机变量不确定性的描述</strong>。</p>
<p><em>通信系统的基本模型为：信源→信源编码→加密→信道编码→信道→信道译码→解密→信源译码→信宿</em></p>
<p>我们所研究的内容以最基础的简单通信系统为例即可：</p>
<p><strong>信源→信道→信宿</strong></p>
<p>信源是通信系统的发射端。</p>
<p>信宿是通信系统的接收端。</p>
<p>消息是信息的载体。</p>
<p>信源是随机的，</p>
<p>信道的影响是随机的，信宿也就是随机的。</p>
<p>之后的内容基本上就围绕上述模型展开进行研究。</p>
<p>主要以<strong>香农信息论</strong>为主。</p>
<hr>
<h2 id="信源"><a href="#信源" class="headerlink" title="信源"></a>信源</h2><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>既然需要研究信源，则首先需要理解我们研究信源特性的动机：</p>
<p>※提高信源效率，尽可能使其适用于传输</p>
<p>※进行编码，以便“一切尽在不言中”（老师PPT里的原话，不明白啥意思😋😋😋）</p>
<hr>
<h3 id="信源的分类"><a href="#信源的分类" class="headerlink" title="信源的分类"></a>信源的分类</h3><p>✧<strong>离散&#x2F;连续（数字&#x2F;模拟）</strong>——根据信源的时间、相位、频率、幅度分布特性</p>
<p>✧<strong>二进制&#x2F;多进制</strong> —— 根据数字信源的消息集合大小</p>
<p>✧<strong>无记忆&#x2F;有记忆</strong> —— 离散信源产生的消息序列的内部关联性</p>
<p>✧<strong>离散&#x2F;连续 &amp;  平稳&#x2F;非平稳</strong> —— 离散信源的随机过程</p>
<hr>
<h2 id="单符号离散信源☜☜☜"><a href="#单符号离散信源☜☜☜" class="headerlink" title="单符号离散信源☜☜☜"></a>单符号离散信源☜☜☜</h2><p><u>如果信源每次发出的消息都是单一符号， 而这些符号的取值是有限或可数的，则称这种信源为单符号离散信源。</u>(e.g. 扔骰子、普通的天气气象)</p>
<p>以扔骰子为例，我们可以将这一单符号离散信源表示为：<br>$$<br>\left[ \begin{array}{c}X \\ P(X)\end{array}<br>\right]&#x3D;\left[\begin{array}{c} 1 &amp;2  &amp;3  &amp;4  &amp;5  &amp; 6 \\  \frac{1}{6} &amp;  \frac{1}{6}&amp;  \frac{1}{6}&amp;  \frac{1}{6}&amp;  \frac{1}{6}&amp;\frac{1}{6}\end{array}\right]<br>$$<br>进行广义上的定义如下：<br>$$<br>\left[\begin{matrix}X \\ P(X)\end{matrix}\right]&#x3D;\left[\begin{matrix} x_{1} &amp;x_{2}  &amp;x_{3}  &amp;… &amp; x_{n} \\   P(x_{1}) &amp;  P(x_{2})&amp;  P(x_{3})&amp;  …  &amp;P(x_{n})\end{matrix}\right]<br>$$<br><em>(注：此处需要概率论知识：①联合概率；②条件概率)</em></p>
<hr>
<h3 id="自信息量☜☜☜"><a href="#自信息量☜☜☜" class="headerlink" title="自信息量☜☜☜"></a>自信息量☜☜☜</h3><p>此处有关自信息量定义过程稍微有点冗杂（其实是笔者太懒不想看），可以这样理解：消息中包含的不确定性的成分是信息，<strong>不确定性的成分越大（出现的概率越小），信息量就越大</strong>，之后我们便可以考虑这个量是多少，应该如何表示了。</p>
<p><strong>基于离散信源</strong>，$x_{i}$ 所包含的信息量为$I(x_{i})$ ，其需要满足如下条件（为什么要满足这些条件我也不太清楚）：</p>
<p>①$I(x_{i})$与$x_{i}$的概率$P(x_{i})$相关</p>
<p>②$I(x_{i})$是$P(x_{i})$的连续函数</p>
<p>③$I(x_{i})$是$P(x_{i})$的减函数，且当$P(x_{i})$&#x3D;1时$I(x_{i})$&#x3D;0</p>
<p>对以上条件进行数学建模，可以得到<strong>自信息量的定义为</strong>：<br>$$<br>I(x_{i})&#x3D;-log_xP(x_{i})<br>$$<br>根据对数底数的不同，自信息量的单位不同：</p>
<p>2——比特（bit）</p>
<p>e——奈特（nat）</p>
<p>10——哈特（Hart）</p>
<p>目前的通信系统或其他信息传输系统大多 以二进制为基础，<strong>因此信息量的单位以bit 最为常用</strong>。即：<br>$$<br>I(x_{i})&#x3D;-log_2P(x_{i})&#x3D;-lbP(x_{i})<br>$$<br><em>注：此处 lb的写法是log binary</em></p>
<p>其性质按照普通对数函数结合$P(x_{i})$的性质取值特征进行讨论即可，不多做赘述。</p>
<hr>
<h3 id="互信息量"><a href="#互信息量" class="headerlink" title="互信息量"></a>互信息量</h3><p>之后讨论，此处不多做赘述😏😏😏。</p>
<hr>
<h3 id="信息熵☜☜☜"><a href="#信息熵☜☜☜" class="headerlink" title="信息熵☜☜☜"></a>信息熵☜☜☜</h3><p>一个单符号离散信源发出的各种消息——自信息量</p>
<p>该信源整体的信息量如何度量——？？？</p>
<p>引入<strong>信息熵，其定义为</strong>：</p>
<p>$H(X)&#x3D;E[I(x_{i})]&#x3D;\sum_{i&#x3D;1}^{n}P(x_{i})I(x_{i})&#x3D;-\sum_{i&#x3D;1}^{n}P(x_{i})lbP(x_{i})$</p>
<p><em>可以从统计的角度出发：根据概率论的知识可知：数学期望反映了随机变量的统计特性，类比至信息量与信息熵即可理解</em></p>
<p>◼信源熵H(X)表示信源输出后，<u>平均</u>每个离散消息所提供的信息量。</p>
<p> ◼ 信源熵H(X)表示信源输出前，信源的<u>平均</u>不确定度。</p>
<p> ◼ 信源熵H(X)反映了变量X的<u>随机性</u>。</p>
<p><strong>信息熵的单位为：比特&#x2F;符号（bit&#x2F;symbol）</strong></p>
<p>其性质有：非负性、严格上凸性、<strong>最大熵定理</strong></p>
<p>最大熵定理为(证明过程略，但是比较重要)：<br>$$<br>H(X)\le lb(n)   \enspace\enspace or\enspace\enspace H(X)\le log_{2}n<br>$$</p>
<hr>
<h2 id="多符号离散信源☜☜☜"><a href="#多符号离散信源☜☜☜" class="headerlink" title="多符号离散信源☜☜☜"></a>多符号离散信源☜☜☜</h2><p>定义如下：如果任何时刻信源发出的消息都是<strong>有限或可数的符号序列</strong>，而<strong>每个符号都取值于同一个有限或可数的集合</strong>，则称这种信源为多符号离散信源。</p>
<p>(e.g. 掷多个色子，再比如发短消息，每条短消息只包含多个字)</p>
<p>多符号（N）离散信源发出的符号序列记为<br>$$<br>X_{1}X_{2}X_{3}…X_{N}<br>$$<br>序列中的任一符号取值于集合：<br>$$<br>X_{k}\in  { x_{1} , x_{2},…,x_{n}  }, k&#x3D;1, 2, …<br>$$</p>
<hr>
<h3 id="二维离散平稳信源"><a href="#二维离散平稳信源" class="headerlink" title="二维离散平稳信源"></a>二维离散平稳信源</h3><p>数学模型为：<br>$$<br>\left[\begin{matrix}X_{1}X_{2} \\ P(X_{1}X_{2})\end{matrix}\right]&#x3D;\left[\begin{matrix} a_{1} &amp;a_{2}   &amp;… &amp; a_{n^{2}} \\   P(a_{1}) &amp;  P(a_{2}) &amp;  …  &amp;P(a_{n^{2}})\end{matrix}\right]<br>$$<br>信息熵为：<br>$$<br>H(X_{1}X_{2})&#x3D;-\sum_{i&#x3D;1}^{n^{2}}P(a_{i})lbP(a_{i})<br>$$<br>中间有一段推导过程，此处省略，最终可以得到：<br>$$<br>H(X_{1}X_{2})&#x3D;H(X_{1})+H(X_{2}&#x2F;X_{1})<br>$$<br>其中：</p>
<p>$H(X_{1})、H(X_{2})$			→			<u>无条件熵</u></p>
<p>$H(X_{1}X_{2})$				   	→			<u>联合熵</u></p>
<p>$H(X_{2}&#x2F;X_{1})$	                 →			<u>条件熵</u></p>
<p>通过数学方法可以证明：<br>$$<br>H(X_{1}X_{2}) \le H(X_{1})+H(X_{2})&#x3D;2H(x_{1})<br>$$<br>如果将该信源符号所提供的平均信息量记为$H_{2}(X_{1}X_{2})$并称其为<strong>平均符号熵</strong>，也叫熵率，则:<br>$$<br>H_{2}(X_{1}X_{2}) &#x3D; \frac{1}{2}H(X_{1}X_{2}) \le H(x_{1})<br>$$</p>
<hr>
<h3 id="多符号离散平稳信源"><a href="#多符号离散平稳信源" class="headerlink" title="多符号离散平稳信源"></a>多符号离散平稳信源</h3><p>对于多符号离散信源发出的符号序列：<br>$$<br>X_{1}X_{2}X_{3}…X_{N}<br>$$<br>如果有两个不同的时刻k和l，其中<br>$$<br>k&#x3D;1, 2, … \enspace\enspace\enspace l&#x3D;1, 2, …<br>$$<br>且概率分布相同，即：<br>$$<br>P(X_{k})&#x3D;P(X_{l})<br>$$<br>则称该多符号离散信源为<strong>一维离散平稳信源</strong></p>
<hr>
<p>同时如果其二维联合概率分布也相同，即<br>$$<br>P(X_{k})&#x3D;P(X_{l}) \\<br>P(X_{k}X_{k+1})&#x3D;P(X_{l}X_{l+1})<br>$$<br>则称该多符号离散信源为<strong>二维离散平稳信源</strong></p>
<hr>
<p>拓展到N维：<br>$$<br>P(X_{k})&#x3D;P(X_{l}) \\<br>P(X_{k}X_{k+1})&#x3D;P(X_{l}X_{l+1}) \\<br>… \\<br>P(X_{k}X_{k+1}…X_{k+N-1})&#x3D;P(X_{l}X_{l+1}…X_{l+N-1})<br>$$<br>则称该多符号离散信源为<strong>N维离散平稳信源</strong></p>
<p><u><strong>注意：直到N维的各维联合概率分布都与时间起点无关。</strong></u></p>
<hr>
<p>由此得到其数学模型：<br>$$<br>\left[\begin{matrix}X_{1}X_{2}…X_{N} \\ P(X_{1}X_{2}…X_{N})\end{matrix}\right]&#x3D;\left[\begin{matrix} a_{1} &amp;a_{2}   &amp;… &amp; a_{n^{N}} \\   P(a_{1}) &amp;  P(a_{2}) &amp;  …  &amp;P(a_{n^{N}})\end{matrix}\right]<br>$$<br>其中，<br>$$<br>a_{i}&#x3D;x_{i_{1}}x_{i_{2}}…x_{i_{N}} \\<br>P(a_{i}) &#x3D;P(x_{i_{1}}x_{i_{2}}…x_{i_{N}})&#x3D;P(x_{i_{1}})P(x_{i_{2}}&#x2F;x_{i_{1}})P(x_{i_{N}}&#x2F;x_{i_{1}}x_{i_{2}}…x_{i_{N-1}})<br>$$</p>
<hr>
<h4 id="多符号离散平稳信源的信息熵"><a href="#多符号离散平稳信源的信息熵" class="headerlink" title="多符号离散平稳信源的信息熵"></a>多符号离散平稳信源的信息熵</h4><p>联合自信息量:<br>$$<br>I(a_{i})&#x3D;I(x_{i_{1}},x_{i_{2}},..,x_{i_{N}})&#x3D;-lbP(x_{i_{1}},x_{i_{2}},..,x_{i_{N}})<br>$$<br>条件信息量：<br>$$<br>I(x_{i_{N}}&#x2F;x_{i_{1}},..,x_{i_{N-1}})&#x3D;-lbP(x_{i_{N}}&#x2F;x_{i_{1}},..,x_{i_{N-1}})<br>$$<br>信息熵：<br>$$<br>H(X_{1}X_{2}…X_{N})&#x3D;H(X_{1})+H(X_{2}&#x2F;X_{1})+…+H(X_{N}&#x2F;X_{1}X_{2}…X_{N-1})<br>$$</p>
<p>$$<br>H(X_{1}X_{2}…X_{N})&#x3D;\frac{1}{N}H(X_{1}X_{2}…X_{N}) \le H(X_{1})<br>$$</p>
<p>当$N→\infty$时，平均符号熵取极限值，成为<strong>极限熵</strong>：<br>$$<br>H_{\infty}&#x3D;\lim_{N→\infty}H(X_{1}X_{2}…X_{N})&#x2F;N&#x3D;\lim_{N→\infty}H(X_{N}&#x2F;X_{1}X_{2}…X_{N-1})<br>$$</p>
<hr>
<h3 id="多符号离散平稳无记忆信源"><a href="#多符号离散平稳无记忆信源" class="headerlink" title="多符号离散平稳无记忆信源"></a>多符号离散平稳无记忆信源</h3><p>如果离散平稳信源发出的符号序列中各符号<u>相互独立</u>，则称该信源为**<u>离散平稳无记忆信源</u>**。</p>
<p>根据N维离散平稳信源数学模型：<br>$$<br>\left[\begin{matrix}X_{1}X_{2}…X_{N} \\ P(X_{1}X_{2}…X_{N})\end{matrix}\right]&#x3D;\left[\begin{matrix} a_{1} &amp;a_{2}   &amp;… &amp; a_{n^{N}} \\   P(a_{1}) &amp;  P(a_{2}) &amp;  …  &amp;P(a_{n^{N}})\end{matrix}\right]<br>$$<br>其中，<br>$$<br>a_{i}&#x3D;x_{i_{1}}x_{i_{2}}…x_{i_{N}} \\<br>$$</p>
<p>$$<br>P(a_{i}) &#x3D;P(x_{i_{1}}x_{i_{2}}…x_{i_{N}})&#x3D;P(x_{i_{1}})P(x_{i_{2}}&#x2F;x_{i_{1}})P(x_{i_{N}}&#x2F;x_{i_{1}}x_{i_{2}}…x_{i_{N-1}})<br>$$</p>
<hr>
<p>如果各个符号相互独立，则有：<br>$$<br>P(a_{i}) &#x3D;P(x_{i_{1}}x_{i_{2}}…x_{i_{N}})&#x3D;P(x_{i_{1}})P(x_{i_{2}})…P(x_{i_{N}})<br>$$<br><strong><u>相当于一维离散平稳信源扩展N次，也叫N次扩展信源。</u></strong></p>
<hr>
<p>由此我们可以得到N维离散平稳无记忆信源数学模型：<br>$$<br>\left[\begin{matrix}X^{N} \\ P(X^{N})\end{matrix}\right]&#x3D;\left[\begin{matrix} a_{1} &amp;a_{2}   &amp;… &amp; a_{n^{N}} \\   P(a_{1}) &amp;  P(a_{2}) &amp;  …  &amp;P(a_{n^{N}})\end{matrix}\right]<br>$$</p>
<p>$$<br>P(a_{i}) &#x3D;P(x_{i_{1}}x_{i_{2}}…x_{i_{N}})&#x3D;P(x_{i_{1}})P(x_{i_{2}})…P(x_{i_{N}})<br>$$</p>
<hr>
<p>信息熵：<br>$$<br>H(X^{N})&#x3D;H(X_{1})+H(X_{2})+…+H(X_{N})&#x3D;NH(X_{1})<br>$$<br>平均符号熵：<br>$$<br>H_{N}(X^{N})&#x3D;\frac{1}{N}(X_{N})&#x3D;H(X_{1})<br>$$<br>极限熵：<br>$$<br>H_{\infty}&#x3D;\lim_{N→\infty}\frac{1}{N}H(X_{N})&#x3D;\lim_{N→\infty}H(X_{1})&#x3D;H(X_{1})<br>$$</p>
<hr>
<h3 id="马尔科夫（Markov）信源"><a href="#马尔科夫（Markov）信源" class="headerlink" title="马尔科夫（Markov）信源"></a>马尔科夫（Markov）信源</h3><p>如果离散平稳信源发出的符号只与前面已经发出的m(&lt;N)个符号相关，则称该信源为m阶马尔科夫信源。</p>
<p><strong>马尔科夫信源是<u>离散平稳有限记忆信源</u> ，马尔科夫信源的记忆长度为 m 。</strong></p>
<p>它产生的符号序列的<u><strong>符号之间有相关性</strong></u>。</p>
<hr>
<p>数学模型为：<br>$$<br>\left[\begin{matrix}X_{m+1}&#x2F;X_{1}X_{2}…X_{N} \\ P(X_{m+1}&#x2F;X_{1}X_{2}…X_{N})\end{matrix}\right]&#x3D;\left[\begin{matrix} a_{1} &amp;a_{2}   &amp;… &amp; a_{n^{m+1}} \\   P(a_{1}) &amp;  P(a_{2}) &amp;  …  &amp;P(a_{n^{m+1}})\end{matrix}\right]<br>$$<br>其中，<br>$$<br>a_{i}&#x3D;x_{i_{m+1}}&#x2F;x_{i_{1}}x_{i_{2}}…x_{i_{N}} \\<br>$$</p>
<p>$$<br>P(a_{i}) &#x3D;P(x_{i_{m+1}}&#x2F;x_{i_{1}}x_{i_{2}}…x_{i_{m}})<br>$$</p>
<hr>
<p>引入状态序列，其数学模型可以描述为：<br>$$<br>\left[\begin{matrix}S_{m+1}&#x2F;S_{m} \\ P(S_{m+1}&#x2F;S_{m})\end{matrix}\right]&#x3D;\left[\begin{matrix} e_{1}&#x2F;e_{1} &amp;e_{2}&#x2F;e_{1}  &amp;… &amp; e_{n^{m}-1}&#x2F;e_{n^{m}}&amp;e_{n^{m}}&#x2F;e_{n^{m}} \\   P(e_{1}&#x2F;e_{1}) &amp;  P(e_{2}&#x2F;e_{1}) &amp;  …  &amp;P(e_{n^{m}-1}&#x2F;e_{n^{m}})&amp;e_{n^{m}}&#x2F;e_{n^{m}}\end{matrix}\right]<br>$$<br>且<br>$$<br>\sum_{j&#x3D;1}^{n}P(e_{j}&#x2F;e_{i})&#x3D;1<br>$$<br><strong><u>此类例题一般使用状态转移图解决！！！</u></strong></p>
<hr>
<p>极限熵：<br>$$<br>H_{\infty}&#x3D;H_{m+1}&#x3D;-\sum_{i&#x3D;1}^{n^{m}}\sum_{j&#x3D;1}^{n^{m}}P(e^{i})P(e^{j}&#x2F;e^{i})lbP(e^{j}&#x2F;e^{i})<br>$$</p>
<hr>
<p>信息冗余度——懒了没看</p>
<p>信源符号序列分组定理——懒了没看</p>
<p>无失真编码定理——懒了没看</p>
<h1 id="Chapter-2-无失真信源编码"><a href="#Chapter-2-无失真信源编码" class="headerlink" title="Chapter 2 无失真信源编码"></a>Chapter 2 无失真信源编码</h1><h2 id="前言-1"><a href="#前言-1" class="headerlink" title="前言"></a>前言</h2><p>信息传输的3个关键要求——**<u>效率、可靠、安全</u>**。</p>
<p><u><strong>信源编码</strong></u>：为了满足信道特性，往往需要**<u>将n元的信源符号序列变换为m元(一般为二元)</u>** 的信源码序列的过程。</p>
<p>无失真——编码和译码过程中不丢失信息。</p>
<h2 id="无失真信源编码"><a href="#无失真信源编码" class="headerlink" title="无失真信源编码"></a>无失真信源编码</h2><p>保证符号元与码字一一对应，此时用码序列表示的信源信息熵保持不变。</p>
<p>例题：<br>$$<br>\left[ \begin{array}{c}X \\ P(X)\end{array}<br>\right]&#x3D;\left[\begin{array}{c} x_{1} &amp;x_{2}  &amp;x_{3}  &amp;x_{4} \\  0.5{6}&amp;  0.3&amp;  0.15&amp;0.05\end{array}\right]<br>$$<br><em>最简单的无失真编码：4–2进制变换</em><br>$$<br>x_{1}→00， x_{2}→01，x_{3}→10，x_{4}→11<br>$$<br>编码的码长K&#x3D;2,其编码效率为：<br>$$<br>\eta&#x3D;\frac{H(X)}{K}\approx 82.4%<br>$$<br>考虑到编码效率，此时考虑压缩比特数，进行不等长编码，即（注：下方法无法实现无失真译码）：<br>$$<br>x_{1}→0， x_{2}→1，x_{3}→00，x_{4}→01<br>$$<br>此时一种保证符号元与码字一一对应的不等长编码为：<br>$$<br>x_{1}→0， x_{2}→10，x_{3}→110，x_{4}→111<br>$$<br>编码的码长：<br>$$<br>\overline{K} &#x3D;0.5\times 1+0.32\times 2+0.15\times3+0.05\times 2&#x3D;1.7<br>$$<br>其编码效率为：<br>$$<br>\eta&#x3D;\frac{H(X)}{K}\approx 96.9%<br>$$</p>
<hr>
<h3 id="信源二次扩展"><a href="#信源二次扩展" class="headerlink" title="信源二次扩展"></a>信源二次扩展</h3><p>将信源进行二维拓展组合即可。</p>
<hr>
<p>一些小结论：<br>        ①不等长编码的平均码长可以是小数比特。</p>
<p>②<strong>大概率符号序列编为短码、小概率符号序列编为长码有助 于压缩平均码长。</strong></p>
<p>③ <strong>信源的N次扩展有助于压缩平均码长，随N的增大，可以预 见码率可能渐进达到信源编码的下界。</strong></p>
<p>④出现无失真译码问题——由于码长不等，接收端如何从码 序列串中唯一分割出对应与每一个符号序列的码字。</p>
<h2 id="无失真编码定理"><a href="#无失真编码定理" class="headerlink" title="无失真编码定理"></a>无失真编码定理</h2><h3 id="一些概念"><a href="#一些概念" class="headerlink" title="一些概念"></a>一些概念</h3><p>如果所采用的不等长编码使接收端能从码序列中唯一地分割出对应与每一个符号元的码字，则称该不等长编码为单义可译码。</p>
<p> <strong><u>单义可译码中，如果能在对应于每一个符号元的码字结束时立即译出的称为即时码，如果要等到对应与下一个符号元的码字才能译出的称为延时码。</u></strong></p>
<p>e.g.<br>$$<br>A:0 , 1, 00, 01 \\<br>B:0, 01, 011, 0111 \\<br>C:0, 10, 110, 111<br>$$<br>A不是单义可译码，有二义性</p>
<p>B是延时码</p>
<p>C是即时码</p>
<p><del>而考试没有码</del></p>
<h3 id="码数图"><a href="#码数图" class="headerlink" title="码数图"></a>码数图</h3><p>类比二叉树，不多做赘述</p>
<h3 id="克拉夫特（Kraft）不等式"><a href="#克拉夫特（Kraft）不等式" class="headerlink" title="克拉夫特（Kraft）不等式"></a>克拉夫特（Kraft）不等式</h3><p>m元长度为$k_{i}, i&#x3D;1, 2, …, n$​的异前置码存在的充分必要条件是：<br>$$<br>\sum_{i&#x3D;1}^{n}m^{-k_{i}} \le 1<br>$$<br>可以这样理解，取m&#x3D;2，先选取0作为其中一个码字，因为Kraft不等式表示的编码方式中每个码字长度不定，因此，每个码字不能是另一个码字的前缀。所以，当我们选取0作为一个码字后，我们就不能再将一个以0开头的二进制串作为码字。</p>
<hr>
<h3 id="无失真编码定理-1"><a href="#无失真编码定理-1" class="headerlink" title="无失真编码定理"></a>无失真编码定理</h3><p>如果$N$维离散平稳信源的平均符号熵为$H_{N}(X_{1}X_{2}…X_{N})$，对信源符号序列进行m元不等长组编码，一定存在一种无失真编码方法，当$N$足够大时，使得每个信源符号序列所对应码字的平均比特数：<br>$$<br>H_{N}(X_{1}X_{2}…X_{N}) \le \frac{\overline{K}}{N}lb \le H_{N}(X_{1}X_{2}…X_{N}) +\varepsilon<br>$$<br>$\varepsilon $为任意给定的小正数。</p>
<p>证明过程略</p>
<h2 id="香农编码"><a href="#香农编码" class="headerlink" title="香农编码"></a>香农编码</h2><p>香农编码的编码步骤如下：<br>        <strong>①将符号元$x_{i}$按概率进行降序排列；</strong></p>
<p><strong>②令$p(x_{0})&#x3D;0$， 计算第$i$个码字的累加概率：</strong><br>$$<br>p_{a}(x_{i})&#x3D;\sum_{j&#x3D;0}^{i-1}p(x_{j}),i&#x3D;1, 2,…, n<br>$$<br>**③确定第$i$个码字的码长$**k_{i}$<br>$$<br>-lbp(x_{i}) \le k_{i} &lt;-lbp(x_{i})+1<br>$$<br><strong>④将$p_{a}(x_{i})$用二进制表示，取小数点后$k_{i}$位作为符号元$x_{i}$的码字</strong></p>
<hr>
<h2 id="霍夫曼-Huffman-编码"><a href="#霍夫曼-Huffman-编码" class="headerlink" title="霍夫曼(Huffman)编码"></a>霍夫曼(Huffman)编码</h2><p>霍夫曼(Huffman)编码的编码步骤如下（其效率高于香农编码）：</p>
<p><strong>①将符号元$x_{i}$按概率进行降序排列；</strong></p>
<p><strong>②为概率最小的符号元分配一个码元1， 概率次小的符号元分配一个码元0；</strong></p>
<p><strong>③将概率最小的两个符号元合并成一个新的符号元，用两者概率之和作为该新 符号元的概率；</strong></p>
<p><strong>④重复以上三个步骤，直到最后合并出一个以1为概率的符号元，结束编码。</strong></p>
<p>e.g.</p>
<p><img src="https://s1.ax1x.com/2023/05/25/p9HZ501.png" alt="p9HZ501.png"></p>
<h1 id="Chapter-3-离散信道与信道容量"><a href="#Chapter-3-离散信道与信道容量" class="headerlink" title="Chapter 3 离散信道与信道容量"></a>Chapter 3 离散信道与信道容量</h1><h2 id="互信息量-1"><a href="#互信息量-1" class="headerlink" title="互信息量"></a>互信息量</h2><p>互信息量是一个随机变量包含另-个随机变量的信息量</p>
<p>或通过一个随机变量获取另一个随机变量所具有的信息量</p>
<p>它反映的也是两个随机变量间的关系；</p>
<hr>
<p>考虑到最简单的通信系统：</p>
<p><strong><u>信源→信道→信宿</u></strong></p>
<p>设单符号离散信源：<br>$$<br>\left[\begin{matrix}X \\ P(X)\end{matrix}\right]&#x3D;\left[\begin{matrix} x_{1} &amp;x_{2}  &amp;… &amp; x_{n} \\   P(x_{1}) &amp;  P(x_{2})&amp;  …  &amp;P(x_{n})\end{matrix}\right]<br>$$<br>单符号离散信宿：<br>$$<br>\left[\begin{matrix}Y \\ P(X)\end{matrix}\right]&#x3D;\left[\begin{matrix} y_{1} &amp;y_{2}  &amp;… &amp; y_{n} \\   P(y_{1}) &amp;  P(y_{2})&amp;  …  &amp;P(y_{n})\end{matrix}\right]<br>$$<br>☻如果是无噪信道，当信源发出x，信宿接收到的也必是x，因此，信道的输出y就等于输入x。</p>
<p>☻如果是有噪信道，信号通过信道就会产生失真，此时，信道的输出y一般不等于 输入x，但它们之间会满足一定关系， 由于噪声的随机性，用条件概率来描述这种关系是恰当的。</p>
<p>故**<u>单符号离散信道的数学模型</u>**可以表示为：</p>
<p>$$<br>P(Y&#x2F;X)&#x3D;\left[\begin{matrix} p(y_{1}&#x2F;x_{1}) &amp;p(y_{2}&#x2F;x_{1})  &amp;… &amp;p(y_{m}&#x2F;x_{1})\\   p(y_{1}&#x2F;x_{2}) &amp;  p(y_{2}&#x2F;x_{2})&amp;  …  &amp;p(y_{m}&#x2F;x_{2})\\<br>  …&amp;  …&amp;  …&amp;  …<br>\\<br>p(y_{1}&#x2F;x_{n}) &amp;  p(y_{2}&#x2F;x_{n})&amp;  …  &amp;p(y_{m}&#x2F;x_{n})<br>\end{matrix}\right]<br>$$</p>
<hr>
<p><strong><u>信源发出$x_{i}$，信宿接收$y_{j}$，所包含的信息量用$I(y_{j};x_{i})$表示，我们称为$x_{i}$对$y_{j}$的互信息量(单位为bit)。</u></strong></p>
<p>数学关系如下：<br>$$<br>I(y_{j};x_{i})&#x3D;I(y_{j})-I(y_{j}&#x2F;x_{i})&#x3D;-lbP(y_{j})+lbP(y_{j}&#x2F;x_{i})&#x3D;lb\frac{P(y_{j}&#x2F;x_{i})}{P(y_{j})}<br>$$<br>其性质略。</p>
<p>无噪信道和信道中断的情况显而易见，不多做赘述。</p>
<p><em>please温习概率论当中的边缘分布知识</em></p>
<h2 id="平均互信息量"><a href="#平均互信息量" class="headerlink" title="平均互信息量"></a>平均互信息量</h2><p>如果将离散信道所有x对y的互信息量在联合概率空间$p(x_{i}y_{j})$的数学期望用$I(Y;X)$来表示并称其为X对Y的平均互信 息量，则平均互信息量的定义为：<br>$$<br>I(Y;X)&#x3D;\sum_{i&#x3D;1}^{n}\sum_{j&#x3D;1}^{m}p(x_{i}y_{j})I(y_{j};x_{i})&#x3D;\sum_{i&#x3D;1}^{n}\sum_{j&#x3D;1}^{m}p(x_{i}y_{j})lb\frac{p(y_{j}&#x2F;x_{i})}{p(y_{j}}<br>$$<br>平均互信息量也称为交互熵，单位为bit&#x2F;symbol。</p>
<hr>
<p>以信源作为参考：<br>$$<br>I(Y;X)&#x3D;H(X)-H(Y&#x2F;X)<br>$$<br>此时的条件熵$H(Y&#x2F;X)$称为<strong>损失熵</strong>，是信道给出的平均“信息”量，也称为<strong>信道疑义度</strong>。</p>
<p>以信宿作为参考：<br>$$<br>I(Y;X)&#x3D;H(Y)-H(Y&#x2F;X)<br>$$<br>此时的条件熵$H(Y&#x2F;X)$称为<strong>噪声熵</strong>，是信道给出的平均“信息”量</p>
<p>以系统作为参考：<br>$$<br>I(Y;X)&#x3D;H(X)+H(Y)-H(XY)<br>$$</p>
<hr>
<p>性质略，但是很重要。</p>
<p><del>太懒了</del></p>
<p>注意p-I(X;Y)与q-I(X;Y)曲线的绘制</p>
<p><strong><u>我们可以将平均互信息量理解为信道的信息传输率（不是信息传输速率）。</u></strong></p>
<h2 id="信道容量"><a href="#信道容量" class="headerlink" title="信道容量"></a>信道容量</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>定义：信道转移概率分布P(Y&#x2F;X)不变时，**<u>平均互信息的最大值为信道容量</u>**，用C表示。<br>$$<br>C&#x3D;\underset{P(X)}\max I(X;Y)<br>$$<br>其中P(X)为使I(X;Y)最大的信源概率分布。</p>
<p>单位是bit&#x2F;symbol</p>
<p>顺水推舟，定义最大的信息传输速率为：<br>$$<br>C_{t}&#x3D;\frac{1}{t}\underset{P(X)}\max I(X;Y)<br>$$<br>单位是bit&#x2F;sec</p>
<hr>
<p><del>拉格朗日极值方法计算信道容量的过程略。</del></p>
<h3 id="计算步骤"><a href="#计算步骤" class="headerlink" title="计算步骤"></a>计算步骤</h3><p>①由<br>$$<br>\sum_{j&#x3D;1}^{m}P(y_{j}&#x2F;x_{k})\beta_{j}&#x3D;\sum_{j&#x3D;1}^{m}P(y_{j}&#x2F;x_{k})lbP(y_{j}&#x2F;x_{k})<br>$$<br>求出$\beta_{j}$，$k&#x3D;1, 2, …, n$</p>
<p>②求出：<br>$$<br>C&#x3D;lb(\sum_{j&#x3D;1}^{m}2^{\beta_{j}})<br>$$<br>③求出：<br>$$<br>P(y_{j})&#x3D;2^{\beta_{j}-C}<br>$$<br>④由<br>$$<br>P(y_{j})&#x3D;\sum_{i&#x3D;1}^{n}P(x_{i})P(y_{j}&#x2F;x_{i})<br>$$<br>求出$P(x_{k})$，$k&#x3D;1, 2, …, n$</p>
<h3 id="均匀信道的信道容量"><a href="#均匀信道的信道容量" class="headerlink" title="均匀信道的信道容量"></a>均匀信道的信道容量</h3><p>很重要。</p>
<h3 id="对称信道的信道容量"><a href="#对称信道的信道容量" class="headerlink" title="对称信道的信道容量"></a>对称信道的信道容量</h3><p>Very important.</p>
<h3 id="单符号离散信道的信道容量"><a href="#单符号离散信道的信道容量" class="headerlink" title="单符号离散信道的信道容量"></a>单符号离散信道的信道容量</h3><p>とても重要です。</p>
<h3 id="多符号离散信道的信道容量"><a href="#多符号离散信道的信道容量" class="headerlink" title="多符号离散信道的信道容量"></a>多符号离散信道的信道容量</h3><p>Molto importante.</p>
<h3 id="离散无记忆信道的信道容量"><a href="#离散无记忆信道的信道容量" class="headerlink" title="离散无记忆信道的信道容量"></a>离散无记忆信道的信道容量</h3><p>Очень важно.</p>
<h1 id="Chapter-4-信道编码"><a href="#Chapter-4-信道编码" class="headerlink" title="Chapter 4 信道编码"></a>Chapter 4 信道编码</h1><h2 id="前言-2"><a href="#前言-2" class="headerlink" title="前言"></a>前言</h2><p>🥴怎样通过编码，使在信道中传输的消息发生的错误减少到可以接受的程度，进而能否实现无错误传输？🥴</p>
<hr>
<h2 id="纠错编码的基本思路"><a href="#纠错编码的基本思路" class="headerlink" title="纠错编码的基本思路"></a>纠错编码的基本思路</h2><p>一个BSC的例子</p>
<p>设计译码规则A、B</p>
<p>分别求解平均错误概率</p>
<p>发现错误概率既与信道特性有关也与译码规则有关，故称为**<u>译码错误概率</u>**。</p>
<p>所以<strong>译码规则的设计应该依据最小错误概率准则进行。</strong></p>
<p><del>u1s1，懒得不想看这个思路，他妈的，考试时间紧张，不多做赘述。</del>🤡</p>
<hr>
<h2 id="信道编码定理"><a href="#信道编码定理" class="headerlink" title="信道编码定理"></a>信道编码定理</h2><p>对于离散无记忆信道，如其信道容量为 C，只要信息传输率R&lt;C，一定存在一种编码，当N足够大时，使得译码错误概率$P_{e}$&lt; ε，其中ε为任意给定的小正数.</p>
<p>信道编码定理指出，信道容量C是一个界限，如果信息传输率超过此界限就会出错。</p>
<p>但是信道编码定理没有给出编制纠错码的方法，于是就需要进行后续的讨论。</p>
<h2 id="这是一个有关分类的导引"><a href="#这是一个有关分类的导引" class="headerlink" title="这是一个有关分类的导引"></a>这是一个有关分类的导引</h2><p>根据**<u>纠错方式</u>**分类：</p>
<p>✂检错重发（Auto Retransmission with Request, ARQ）</p>
<p>✂前向纠错（Forward Error Correction, FEC）</p>
<p>✂混合纠错 (Hybrid Error Correction, HEC)</p>
<hr>
<p>根据**<u>纠错码</u>**分类：</p>
<p><strong>⚔</strong><strong><u>线性分组码（汉明码属于线性分组码）</u></strong></p>
<p><strong>⚔</strong>卷积码</p>
<p><strong>⚔</strong>Turbo码</p>
<p><strong>⚔</strong>LDPC码</p>
<p><strong>⚔</strong> Polar码</p>
<p>其中线性分组码表示为（n,k）</p>
<p>n为码字长度</p>
<p>k为信息位长度</p>
<p>n-k为校验位长度</p>
<h2 id="这是一些重要概念的介绍"><a href="#这是一些重要概念的介绍" class="headerlink" title="这是一些重要概念的介绍"></a>这是一些重要概念的介绍</h2><h3 id="码距（汉明距离）"><a href="#码距（汉明距离）" class="headerlink" title="码距（汉明距离）"></a>码距（汉明距离）</h3><p>在$m&#x3D;2^{k}$个码字构成的码中，两个长度为n的码字之间的汉明距离(码距)是指两个码字对应位置上不同码元的个数(<strong><u>其实就是数俩码字之间有多少码元不一样</u></strong>)。</p>
<p>以二元码为例，码距可表示为：<br>$$<br>d(c_{i},d_{j})&#x3D;\sum_{k&#x3D;1}^{n}c_{i_{k}}\oplus c_{j_{k}}<br>$$<br>其中<br>$$<br>i,j&#x3D;1, 2, …, m  且i\ne j<br>$$<br>e.g.(1)</p>
<p>$$<br>c_{1}&#x3D;1310120 \\<br>c_{2}&#x3D;1220310 \\<br>d(c_{1}, c_{2})&#x3D;3<br>$$</p>
<h3 id="最小码距"><a href="#最小码距" class="headerlink" title="最小码距"></a>最小码距</h3><p>在m个码字构成的码中，任意两个码字之间码距的最小值称为该码的最小距离。</p>
<p>编码原则是要保证最小码距足够大</p>
<h3 id="错误图案"><a href="#错误图案" class="headerlink" title="错误图案"></a>错误图案</h3><p>略</p>
<h3 id="联合渐进均分性定理"><a href="#联合渐进均分性定理" class="headerlink" title="联合渐进均分性定理"></a>联合渐进均分性定理</h3><p>略</p>
<h3 id="费诺不等式"><a href="#费诺不等式" class="headerlink" title="费诺不等式"></a>费诺不等式</h3><p>略</p>
<h2 id="线性分组码"><a href="#线性分组码" class="headerlink" title="线性分组码"></a>线性分组码</h2><h3 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h3><p>针对码字个数为$2^k$，码字长度为$n$的码组，若这$2^k$个 码字是GF(2)上n维矢量空间的一个k维子空间时， 称为(n,k)线性分组码，简称(n,k)码。</p>
<p>定义码率为：$R&#x3D;K&#x2F;n$</p>
<p><u><strong>请复习线性代数向量空间的知识！！！</strong></u></p>
<p>可参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/161572740">信道编码系列(四)：线性分组码(Linear Block code)基础 - 知乎 (zhihu.com)</a></p>
<hr>
<h3 id="系统码"><a href="#系统码" class="headerlink" title="系统码"></a>系统码</h3><p>如果码字有两部分组成：</p>
<p>第一部分与输入信息序列相同(称为信息位)</p>
<p>第二部分为校验位</p>
<p>具有这个结构的码字称为系统码</p>
<h3 id="线性分组码——编码"><a href="#线性分组码——编码" class="headerlink" title="线性分组码——编码"></a>线性分组码——编码</h3><p>输入k位信息：<br>$$<br>\mathbf{u}&#x3D;[u_1, u_2, …, u_k]<br>$$<br>输入n长码字：<br>$$<br>\mathbf{c}&#x3D;[c_1, c_2, …, c_k]<br>$$<br>规定生成矩阵：<br>$$<br>G&#x3D;\left[\begin{matrix}\mathbf{g_1} \\\mathbf{g_2}\\<br>:\\\mathbf{g_k}<br>\end{matrix}\right]&#x3D;<br>\left[\begin{matrix} g_{11} &amp;g_{12}  &amp;… &amp;g_{1n}\\  g_{21} &amp;  g_{22}&amp;  …  &amp;g_{2n}\\<br>  …&amp;  …&amp;  …&amp;  …<br>\\<br> g_{k1} &amp; g_{k2}&amp;  …  &amp;g_{kn}<br>\end{matrix}\right]<br>$$<br>此时，有编码码字：<br>$$<br>\mathbf{c}&#x3D;\mathbf{u}\mathbf{G}<br>$$<br>即：<br>$$<br>\mathbf{c}&#x3D;u_1\mathbf{g_1}+u_2\mathbf{g_2}+…+u_k\mathbf{g_k}<br>$$<br>码字是</p>
<p>线性无关矢量的线性组合</p>
<h3 id="线性分组码——译码"><a href="#线性分组码——译码" class="headerlink" title="线性分组码——译码"></a>线性分组码——译码</h3><p>接收码字矢量：$\mathbf{r}$</p>
<p>校验矩阵：$\mathbf{H}, \mathbf{GH^{T}&#x3D;0}$</p>
<p>伴随式矢量：$\mathbf{s}&#x3D; \mathbf{rH^{T}&#x3D;(c+e)H^{T}&#x3D;eH^{T}}$</p>
<p>校验：$\mathbf{s}&#x3D;0$无误，否则有误</p>
<p>纠错：$\mathbf{s}$只和所接受的误码的错误图案有关且一一对应，<br>$$<br>\mathbf{c&#x3D;r+e}<br>$$</p>
<h1 id="Chapter-5-连续信源"><a href="#Chapter-5-连续信源" class="headerlink" title="Chapter 5 连续信源"></a>Chapter 5 连续信源</h1><h2 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h2><p>如果任何是颗信源发出的消息都是单一符号，二这些服啊后的取值是连续的，则该信源位单符号连续信源。</p>
<p>时不变连续信源的数学模型位：<br>$$<br>\left[\begin{matrix}X\\ P(X)\end{matrix}\right]&#x3D;\left[\begin{matrix} a\le x\le b \\   p(x)\end{matrix}\right]<br>$$<br>其中p(x)为概率密度函数，满足积分为1的条件.</p>
<h2 id="连续信源熵（绝对熵）"><a href="#连续信源熵（绝对熵）" class="headerlink" title="连续信源熵（绝对熵）"></a>连续信源熵（绝对熵）</h2><p>$$<br>H(X)&#x3D;-\int_{a}^{b}lbp(x)dx-\lim_{n→\infty}lb\Delta x<br>$$</p>
<h2 id="微分熵（相对熵）"><a href="#微分熵（相对熵）" class="headerlink" title="微分熵（相对熵）"></a>微分熵（相对熵）</h2><p>$$<br>H_{c}(X)&#x3D;-\int_{a}^{b}p(x)lbp(x)dx<br>$$</p>
<h3 id="均匀分布连续信源的相对熵"><a href="#均匀分布连续信源的相对熵" class="headerlink" title="均匀分布连续信源的相对熵"></a>均匀分布连续信源的相对熵</h3><h3 id="高斯分布连续信源的相对熵"><a href="#高斯分布连续信源的相对熵" class="headerlink" title="高斯分布连续信源的相对熵"></a>高斯分布连续信源的相对熵</h3><h3 id="指数分布连续信源的相对熵"><a href="#指数分布连续信源的相对熵" class="headerlink" title="指数分布连续信源的相对熵"></a>指数分布连续信源的相对熵</h3><h2 id="相对熵的性质"><a href="#相对熵的性质" class="headerlink" title="相对熵的性质"></a>相对熵的性质</h2><h3 id="可加性"><a href="#可加性" class="headerlink" title="可加性"></a>可加性</h3><h3 id="不具有非负性"><a href="#不具有非负性" class="headerlink" title="不具有非负性"></a>不具有非负性</h3><h3 id="最大相对熵定理"><a href="#最大相对熵定理" class="headerlink" title="最大相对熵定理"></a>最大相对熵定理</h3><h1 id="Chapter-6-连续信道"><a href="#Chapter-6-连续信道" class="headerlink" title="Chapter 6 连续信道"></a>Chapter 6 连续信道</h1><h2 id="定义-3"><a href="#定义-3" class="headerlink" title="定义"></a>定义</h2><p>对应于时不变连续信源和时不变连续信宿的信道为时不变连续信道。</p>
<p>数学模型如下：<br>$$<br>X→[P(y&#x2F;x)]→Y<br>$$</p>
<h2 id="高斯信道"><a href="#高斯信道" class="headerlink" title="高斯信道"></a>高斯信道</h2><h3 id="定义-4"><a href="#定义-4" class="headerlink" title="定义"></a>定义</h3><h3 id="高斯信道的信道容量"><a href="#高斯信道的信道容量" class="headerlink" title="高斯信道的信道容量"></a>高斯信道的信道容量</h3><h3 id="高斯信道的最大信息传输速率"><a href="#高斯信道的最大信息传输速率" class="headerlink" title="高斯信道的最大信息传输速率"></a>高斯信道的最大信息传输速率</h3><h1 id="Chapter-7-信息率失真理论"><a href="#Chapter-7-信息率失真理论" class="headerlink" title="Chapter 7 信息率失真理论"></a>Chapter 7 信息率失真理论</h1><p>太累了写不下去了，有空了会完善的。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">TrainKing</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2023/10/28/%E4%BF%A1%E6%81%AF%E5%AF%BC%E8%AE%BA/">http://example.com/2023/10/28/%E4%BF%A1%E6%81%AF%E5%AF%BC%E8%AE%BA/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">喜欢我火车王吗？</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://s1.ax1x.com/2023/05/23/p9TireU.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/10/28/%E8%AF%97/"><img class="prev-cover" src="https://s1.ax1x.com/2023/05/23/p9TeMtO.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">一些小诗</div></div></a></div><div class="next-post pull-right"><a href="/2023/10/28/HUAWEI%20ICT/"><img class="next-cover" src="https://s1.ax1x.com/2023/05/23/p9TZBO1.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Information and Communications Technology of HUAWEI</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">TrainKing</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><script src="https://fastly.jsdelivr.net/gh/xiaopengand/blogCdn@latest/xzxr/twopeople1.js"></script><script src="https://fastly.jsdelivr.net/gh/xiaopengand/blogCdn@latest/xzxr/zdog.dist.js"></script><script id="rendered-js" src="https://fastly.jsdelivr.net/gh/xiaopengand/blogCdn@latest/xzxr/twopeople.js"></script><style>.card-widget.card-announcement {
margin: 0;
align-items: center;
justify-content: center;
text-align: center;
}
canvas {
display: block;
margin: 0 auto;
cursor: move;
}</style><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-1-%E7%A6%BB%E6%95%A3%E4%BF%A1%E6%BA%90%E4%B8%8E%E4%BF%A1%E6%81%AF%E7%86%B5"><span class="toc-number">1.</span> <span class="toc-text">Chapter 1 离散信源与信息熵</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF"><span class="toc-number">1.1.</span> <span class="toc-text">信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%A1%E6%BA%90"><span class="toc-number">1.2.</span> <span class="toc-text">信源</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.2.1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%A1%E6%BA%90%E7%9A%84%E5%88%86%E7%B1%BB"><span class="toc-number">1.2.2.</span> <span class="toc-text">信源的分类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%95%E7%AC%A6%E5%8F%B7%E7%A6%BB%E6%95%A3%E4%BF%A1%E6%BA%90%E2%98%9C%E2%98%9C%E2%98%9C"><span class="toc-number">1.3.</span> <span class="toc-text">单符号离散信源☜☜☜</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E4%BF%A1%E6%81%AF%E9%87%8F%E2%98%9C%E2%98%9C%E2%98%9C"><span class="toc-number">1.3.1.</span> <span class="toc-text">自信息量☜☜☜</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%92%E4%BF%A1%E6%81%AF%E9%87%8F"><span class="toc-number">1.3.2.</span> <span class="toc-text">互信息量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E7%86%B5%E2%98%9C%E2%98%9C%E2%98%9C"><span class="toc-number">1.3.3.</span> <span class="toc-text">信息熵☜☜☜</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E7%AC%A6%E5%8F%B7%E7%A6%BB%E6%95%A3%E4%BF%A1%E6%BA%90%E2%98%9C%E2%98%9C%E2%98%9C"><span class="toc-number">1.4.</span> <span class="toc-text">多符号离散信源☜☜☜</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E7%BB%B4%E7%A6%BB%E6%95%A3%E5%B9%B3%E7%A8%B3%E4%BF%A1%E6%BA%90"><span class="toc-number">1.4.1.</span> <span class="toc-text">二维离散平稳信源</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E7%AC%A6%E5%8F%B7%E7%A6%BB%E6%95%A3%E5%B9%B3%E7%A8%B3%E4%BF%A1%E6%BA%90"><span class="toc-number">1.4.2.</span> <span class="toc-text">多符号离散平稳信源</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E7%AC%A6%E5%8F%B7%E7%A6%BB%E6%95%A3%E5%B9%B3%E7%A8%B3%E4%BF%A1%E6%BA%90%E7%9A%84%E4%BF%A1%E6%81%AF%E7%86%B5"><span class="toc-number">1.4.2.1.</span> <span class="toc-text">多符号离散平稳信源的信息熵</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E7%AC%A6%E5%8F%B7%E7%A6%BB%E6%95%A3%E5%B9%B3%E7%A8%B3%E6%97%A0%E8%AE%B0%E5%BF%86%E4%BF%A1%E6%BA%90"><span class="toc-number">1.4.3.</span> <span class="toc-text">多符号离散平稳无记忆信源</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%EF%BC%88Markov%EF%BC%89%E4%BF%A1%E6%BA%90"><span class="toc-number">1.4.4.</span> <span class="toc-text">马尔科夫（Markov）信源</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-2-%E6%97%A0%E5%A4%B1%E7%9C%9F%E4%BF%A1%E6%BA%90%E7%BC%96%E7%A0%81"><span class="toc-number">2.</span> <span class="toc-text">Chapter 2 无失真信源编码</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80-1"><span class="toc-number">2.1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%A0%E5%A4%B1%E7%9C%9F%E4%BF%A1%E6%BA%90%E7%BC%96%E7%A0%81"><span class="toc-number">2.2.</span> <span class="toc-text">无失真信源编码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%A1%E6%BA%90%E4%BA%8C%E6%AC%A1%E6%89%A9%E5%B1%95"><span class="toc-number">2.2.1.</span> <span class="toc-text">信源二次扩展</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%A0%E5%A4%B1%E7%9C%9F%E7%BC%96%E7%A0%81%E5%AE%9A%E7%90%86"><span class="toc-number">2.3.</span> <span class="toc-text">无失真编码定理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5"><span class="toc-number">2.3.1.</span> <span class="toc-text">一些概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A0%81%E6%95%B0%E5%9B%BE"><span class="toc-number">2.3.2.</span> <span class="toc-text">码数图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%8B%E6%8B%89%E5%A4%AB%E7%89%B9%EF%BC%88Kraft%EF%BC%89%E4%B8%8D%E7%AD%89%E5%BC%8F"><span class="toc-number">2.3.3.</span> <span class="toc-text">克拉夫特（Kraft）不等式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A0%E5%A4%B1%E7%9C%9F%E7%BC%96%E7%A0%81%E5%AE%9A%E7%90%86-1"><span class="toc-number">2.3.4.</span> <span class="toc-text">无失真编码定理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A6%99%E5%86%9C%E7%BC%96%E7%A0%81"><span class="toc-number">2.4.</span> <span class="toc-text">香农编码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9C%8D%E5%A4%AB%E6%9B%BC-Huffman-%E7%BC%96%E7%A0%81"><span class="toc-number">2.5.</span> <span class="toc-text">霍夫曼(Huffman)编码</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-3-%E7%A6%BB%E6%95%A3%E4%BF%A1%E9%81%93%E4%B8%8E%E4%BF%A1%E9%81%93%E5%AE%B9%E9%87%8F"><span class="toc-number">3.</span> <span class="toc-text">Chapter 3 离散信道与信道容量</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%92%E4%BF%A1%E6%81%AF%E9%87%8F-1"><span class="toc-number">3.1.</span> <span class="toc-text">互信息量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B3%E5%9D%87%E4%BA%92%E4%BF%A1%E6%81%AF%E9%87%8F"><span class="toc-number">3.2.</span> <span class="toc-text">平均互信息量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%A1%E9%81%93%E5%AE%B9%E9%87%8F"><span class="toc-number">3.3.</span> <span class="toc-text">信道容量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-number">3.3.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%AD%A5%E9%AA%A4"><span class="toc-number">3.3.2.</span> <span class="toc-text">计算步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9D%87%E5%8C%80%E4%BF%A1%E9%81%93%E7%9A%84%E4%BF%A1%E9%81%93%E5%AE%B9%E9%87%8F"><span class="toc-number">3.3.3.</span> <span class="toc-text">均匀信道的信道容量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E7%A7%B0%E4%BF%A1%E9%81%93%E7%9A%84%E4%BF%A1%E9%81%93%E5%AE%B9%E9%87%8F"><span class="toc-number">3.3.4.</span> <span class="toc-text">对称信道的信道容量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%95%E7%AC%A6%E5%8F%B7%E7%A6%BB%E6%95%A3%E4%BF%A1%E9%81%93%E7%9A%84%E4%BF%A1%E9%81%93%E5%AE%B9%E9%87%8F"><span class="toc-number">3.3.5.</span> <span class="toc-text">单符号离散信道的信道容量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E7%AC%A6%E5%8F%B7%E7%A6%BB%E6%95%A3%E4%BF%A1%E9%81%93%E7%9A%84%E4%BF%A1%E9%81%93%E5%AE%B9%E9%87%8F"><span class="toc-number">3.3.6.</span> <span class="toc-text">多符号离散信道的信道容量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A6%BB%E6%95%A3%E6%97%A0%E8%AE%B0%E5%BF%86%E4%BF%A1%E9%81%93%E7%9A%84%E4%BF%A1%E9%81%93%E5%AE%B9%E9%87%8F"><span class="toc-number">3.3.7.</span> <span class="toc-text">离散无记忆信道的信道容量</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-4-%E4%BF%A1%E9%81%93%E7%BC%96%E7%A0%81"><span class="toc-number">4.</span> <span class="toc-text">Chapter 4 信道编码</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80-2"><span class="toc-number">4.1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%A0%E9%94%99%E7%BC%96%E7%A0%81%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF"><span class="toc-number">4.2.</span> <span class="toc-text">纠错编码的基本思路</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%A1%E9%81%93%E7%BC%96%E7%A0%81%E5%AE%9A%E7%90%86"><span class="toc-number">4.3.</span> <span class="toc-text">信道编码定理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%9C%89%E5%85%B3%E5%88%86%E7%B1%BB%E7%9A%84%E5%AF%BC%E5%BC%95"><span class="toc-number">4.4.</span> <span class="toc-text">这是一个有关分类的导引</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%99%E6%98%AF%E4%B8%80%E4%BA%9B%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5%E7%9A%84%E4%BB%8B%E7%BB%8D"><span class="toc-number">4.5.</span> <span class="toc-text">这是一些重要概念的介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A0%81%E8%B7%9D%EF%BC%88%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB%EF%BC%89"><span class="toc-number">4.5.1.</span> <span class="toc-text">码距（汉明距离）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%B0%8F%E7%A0%81%E8%B7%9D"><span class="toc-number">4.5.2.</span> <span class="toc-text">最小码距</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%94%99%E8%AF%AF%E5%9B%BE%E6%A1%88"><span class="toc-number">4.5.3.</span> <span class="toc-text">错误图案</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%94%E5%90%88%E6%B8%90%E8%BF%9B%E5%9D%87%E5%88%86%E6%80%A7%E5%AE%9A%E7%90%86"><span class="toc-number">4.5.4.</span> <span class="toc-text">联合渐进均分性定理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%B9%E8%AF%BA%E4%B8%8D%E7%AD%89%E5%BC%8F"><span class="toc-number">4.5.5.</span> <span class="toc-text">费诺不等式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%88%86%E7%BB%84%E7%A0%81"><span class="toc-number">4.6.</span> <span class="toc-text">线性分组码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-1"><span class="toc-number">4.6.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E7%A0%81"><span class="toc-number">4.6.2.</span> <span class="toc-text">系统码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%88%86%E7%BB%84%E7%A0%81%E2%80%94%E2%80%94%E7%BC%96%E7%A0%81"><span class="toc-number">4.6.3.</span> <span class="toc-text">线性分组码——编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%88%86%E7%BB%84%E7%A0%81%E2%80%94%E2%80%94%E8%AF%91%E7%A0%81"><span class="toc-number">4.6.4.</span> <span class="toc-text">线性分组码——译码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-5-%E8%BF%9E%E7%BB%AD%E4%BF%A1%E6%BA%90"><span class="toc-number">5.</span> <span class="toc-text">Chapter 5 连续信源</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-2"><span class="toc-number">5.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9E%E7%BB%AD%E4%BF%A1%E6%BA%90%E7%86%B5%EF%BC%88%E7%BB%9D%E5%AF%B9%E7%86%B5%EF%BC%89"><span class="toc-number">5.2.</span> <span class="toc-text">连续信源熵（绝对熵）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BE%AE%E5%88%86%E7%86%B5%EF%BC%88%E7%9B%B8%E5%AF%B9%E7%86%B5%EF%BC%89"><span class="toc-number">5.3.</span> <span class="toc-text">微分熵（相对熵）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83%E8%BF%9E%E7%BB%AD%E4%BF%A1%E6%BA%90%E7%9A%84%E7%9B%B8%E5%AF%B9%E7%86%B5"><span class="toc-number">5.3.1.</span> <span class="toc-text">均匀分布连续信源的相对熵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E8%BF%9E%E7%BB%AD%E4%BF%A1%E6%BA%90%E7%9A%84%E7%9B%B8%E5%AF%B9%E7%86%B5"><span class="toc-number">5.3.2.</span> <span class="toc-text">高斯分布连续信源的相对熵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83%E8%BF%9E%E7%BB%AD%E4%BF%A1%E6%BA%90%E7%9A%84%E7%9B%B8%E5%AF%B9%E7%86%B5"><span class="toc-number">5.3.3.</span> <span class="toc-text">指数分布连续信源的相对熵</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E5%AF%B9%E7%86%B5%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="toc-number">5.4.</span> <span class="toc-text">相对熵的性质</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E5%8A%A0%E6%80%A7"><span class="toc-number">5.4.1.</span> <span class="toc-text">可加性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E5%85%B7%E6%9C%89%E9%9D%9E%E8%B4%9F%E6%80%A7"><span class="toc-number">5.4.2.</span> <span class="toc-text">不具有非负性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%A4%A7%E7%9B%B8%E5%AF%B9%E7%86%B5%E5%AE%9A%E7%90%86"><span class="toc-number">5.4.3.</span> <span class="toc-text">最大相对熵定理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-6-%E8%BF%9E%E7%BB%AD%E4%BF%A1%E9%81%93"><span class="toc-number">6.</span> <span class="toc-text">Chapter 6 连续信道</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-3"><span class="toc-number">6.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E4%BF%A1%E9%81%93"><span class="toc-number">6.2.</span> <span class="toc-text">高斯信道</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-4"><span class="toc-number">6.2.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E4%BF%A1%E9%81%93%E7%9A%84%E4%BF%A1%E9%81%93%E5%AE%B9%E9%87%8F"><span class="toc-number">6.2.2.</span> <span class="toc-text">高斯信道的信道容量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E4%BF%A1%E9%81%93%E7%9A%84%E6%9C%80%E5%A4%A7%E4%BF%A1%E6%81%AF%E4%BC%A0%E8%BE%93%E9%80%9F%E7%8E%87"><span class="toc-number">6.2.3.</span> <span class="toc-text">高斯信道的最大信息传输速率</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-7-%E4%BF%A1%E6%81%AF%E7%8E%87%E5%A4%B1%E7%9C%9F%E7%90%86%E8%AE%BA"><span class="toc-number">7.</span> <span class="toc-text">Chapter 7 信息率失真理论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/10/28/%E8%AF%97/" title="一些小诗"><img src="https://s1.ax1x.com/2023/05/23/p9TeMtO.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="一些小诗"/></a><div class="content"><a class="title" href="/2023/10/28/%E8%AF%97/" title="一些小诗">一些小诗</a><time datetime="2023-10-28T06:07:32.285Z" title="发表于 2023-10-28 14:07:32">2023-10-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/10/28/%E4%BF%A1%E6%81%AF%E5%AF%BC%E8%AE%BA/" title="Information Theory and Coding"><img src="https://s1.ax1x.com/2023/05/23/p9TireU.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Information Theory and Coding"/></a><div class="content"><a class="title" href="/2023/10/28/%E4%BF%A1%E6%81%AF%E5%AF%BC%E8%AE%BA/" title="Information Theory and Coding">Information Theory and Coding</a><time datetime="2023-10-28T06:07:32.282Z" title="发表于 2023-10-28 14:07:32">2023-10-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/10/28/HUAWEI%20ICT/" title="Information and Communications Technology of HUAWEI"><img src="https://s1.ax1x.com/2023/05/23/p9TZBO1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Information and Communications Technology of HUAWEI"/></a><div class="content"><a class="title" href="/2023/10/28/HUAWEI%20ICT/" title="Information and Communications Technology of HUAWEI">Information and Communications Technology of HUAWEI</a><time datetime="2023-10-28T06:07:32.278Z" title="发表于 2023-10-28 14:07:32">2023-10-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/10/28/IEICE%E6%9C%9F%E5%88%8A%E6%A8%A1%E6%9D%BF%E8%AF%B4%E6%98%8E%E7%BF%BB%E8%AF%91%EF%BC%88LaTeX%EF%BC%89/" title="IEICE期刊的LaTeX模板使用说明"><img src="https://s1.ax1x.com/2023/05/23/p9TZ2fe.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="IEICE期刊的LaTeX模板使用说明"/></a><div class="content"><a class="title" href="/2023/10/28/IEICE%E6%9C%9F%E5%88%8A%E6%A8%A1%E6%9D%BF%E8%AF%B4%E6%98%8E%E7%BF%BB%E8%AF%91%EF%BC%88LaTeX%EF%BC%89/" title="IEICE期刊的LaTeX模板使用说明">IEICE期刊的LaTeX模板使用说明</a><time datetime="2023-10-28T06:07:32.276Z" title="发表于 2023-10-28 14:07:32">2023-10-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/10/28/%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E5%9C%A8word%E4%B8%AD%E5%86%99latex%E7%9A%84logo/" title="如何“优雅”地在word当中写出LaTeX的logo"><img src="https://s1.ax1x.com/2023/05/23/p9TeD3Q.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="如何“优雅”地在word当中写出LaTeX的logo"/></a><div class="content"><a class="title" href="/2023/10/28/%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E5%9C%A8word%E4%B8%AD%E5%86%99latex%E7%9A%84logo/" title="如何“优雅”地在word当中写出LaTeX的logo">如何“优雅”地在word当中写出LaTeX的logo</a><time datetime="2023-10-28T06:07:32.274Z" title="发表于 2023-10-28 14:07:32">2023-10-28</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://s1.ax1x.com/2023/05/23/p9TireU.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By TrainKing</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a><br>
<a href="http://www.beian.miit.gov.cn/"  style="color:#f72b07" target="_blank">陇ICP备2023002704号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_clock_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><!-- hexo injector body_end end --></body></html>